name: Train model
inputs:
- {name: file, type: Tarball}
- {name: file_csv, type: CSV}
outputs:
- {name: model, type: TFModel}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pandas' 'numpy' 'tensorflow' 'scikit-learn' 'scikit-image' 'keras' 'glob2'
      || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pandas' 'numpy' 'tensorflow' 'scikit-learn' 'scikit-image' 'keras' 'glob2'
      --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n   \
      \ os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
      \ndef train_model(file_path, file_csv, model_path):\n    import os\n    import\
      \ pandas as pd\n    import tarfile\n    import os\n    from glob import glob\n\
      \    from skimage.io import imread\n    import re\n    from sklearn.model_selection\
      \ import train_test_split\n    import numpy as np\n    import keras\n    from\
      \ keras.models import Sequential\n    from keras.layers import Dense, Flatten\n\
      \    from keras.optimizers import Adam\n    from keras.layers import Conv2D,\
      \ MaxPooling2D\n    from pathlib import Path\n\n    BASE_IMG = file_csv\n  \
      \  tarfile.open(name=file_path, mode=\"r|gz\").extractall('data')\n    PATH='data/archive/'\n\
      \    df = pd.read_csv(os.path.join(PATH,\"overview.csv\"), index_col=0)\n  \
      \  df['Contrast'] = df['Contrast'].map(lambda x: 1 if x else 0)\n\n    all_images_list\
      \ = glob(os.path.join(PATH,'tiff_images','*.tif'))\n    np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape\n\
      \    jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)\n    check_contrast\
      \ = re.compile(r'/tiff_images/ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT.tif')\n\
      \n    label = []\n    id_list = []\n    for image in all_images_list:\n    \
      \    id_list.append(check_contrast.findall(image)[0][0])\n        label.append(check_contrast.findall(image)[0][1])\n\
      \n    label_list = pd.DataFrame(label,id_list)\n    images = np.stack([jimread(i)\
      \ for i in all_images_list],0)\n\n    batch_size = 20\n    epochs = 5\n\n  \
      \  X_train, X_test, y_train, y_test = train_test_split(images, label_list, test_size=0.1,\
      \ random_state=0)\n    n_train, depth, width, height = X_train.shape\n    n_test,_,_,_\
      \ = X_test.shape\n    input_shape = (width,height,depth)\n\n    input_train\
      \ = X_train.reshape((n_train, width,height,depth))\n    input_train.astype('float32')\n\
      \    input_train = input_train / np.max(input_train)\n\n    input_test = X_test.reshape(n_test,\
      \ *input_shape)\n    input_test.astype('float32')\n    input_test = input_test\
      \ / np.max(input_test)\n\n    output_train = keras.utils.to_categorical(y_train,\
      \ 2)\n    output_test = keras.utils.to_categorical(y_test, 2)\n\n    model2\
      \ = Sequential()\n    model2.add(Conv2D(50, (5, 5), activation='relu', input_shape=input_shape))\n\
      \    model2.add(MaxPooling2D(pool_size=(3, 3))) \n    model2.add(Conv2D(30,\
      \ (4, 4), activation='relu', input_shape=input_shape))\n    model2.add(MaxPooling2D(pool_size=(2,\
      \ 2)))\n    model2.add(Flatten())\n    model2.add(Dense(2, activation='softmax'))\n\
      \n    model2.compile(loss='categorical_crossentropy',\n                optimizer=Adam(),\n\
      \                metrics=['accuracy'])\n\n    model2.fit(input_train, output_train,\n\
      \                    batch_size=batch_size,\n                    epochs=epochs,\n\
      \                    verbose=1,\n                    validation_data=(input_test,\
      \ output_test))\n\n    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\
      \    model2.save(model_path)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Train\
      \ model', description='')\n_parser.add_argument(\"--file\", dest=\"file_path\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --file-csv\", dest=\"file_csv\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--model\", dest=\"model_path\", type=_make_parent_dirs_and_return_path,\
      \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
      \n_outputs = train_model(**_parsed_args)\n"
    args:
    - --file
    - {inputPath: file}
    - --file-csv
    - {inputPath: file_csv}
    - --model
    - {outputPath: model}
