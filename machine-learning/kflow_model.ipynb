{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_downloader_op = kfp.components.load_component_from_url(\n",
    "    'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/contrib/web/Download/component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(file_path: comp.InputPath('Tarball'),\n",
    "              output_csv: comp.OutputPath('CSV')):\n",
    "  import os\n",
    "  import pandas as pd\n",
    "  import tarfile\n",
    "  import os\n",
    "  from glob import glob\n",
    "  import numpy as np\n",
    "  from skimage.io import imread\n",
    "  import re\n",
    "\n",
    "  tarfile.open(name=file_path, mode=\"r|gz\").extractall('data')\n",
    "  PATH='data/archive/'\n",
    "  df = pd.read_csv(os.path.join(PATH,\"overview.csv\"), index_col=0)\n",
    "  df['Contrast'] = df['Contrast'].map(lambda x: 1 if x else 0)\n",
    "\n",
    "\n",
    "  all_images_list = glob(os.path.join(PATH,'tiff_images','*.tif'))\n",
    "  np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape\n",
    "  jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)\n",
    "  check_contrast = re.compile(r'/tiff_images/ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT.tif')\n",
    "  label = []\n",
    "  id_list = []\n",
    "  for image in all_images_list:\n",
    "    id_list.append(check_contrast.findall(image)[0][0])\n",
    "    label.append(check_contrast.findall(image)[0][1])\n",
    "\n",
    "  label_list = pd.DataFrame(label,id_list)\n",
    "  images = np.stack([jimread(i) for i in all_images_list],0)\n",
    "  \n",
    "  df.to_csv(output_csv, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(file_path: comp.InputPath('Tarball'), file_csv: comp.InputPath('CSV'), model_path: comp.OutputPath('TFModel')):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import tarfile\n",
    "    import os\n",
    "    from glob import glob\n",
    "    from skimage.io import imread\n",
    "    import re\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Flatten\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from pathlib import Path\n",
    "\n",
    "    BASE_IMG = file_csv\n",
    "    tarfile.open(name=file_path, mode=\"r|gz\").extractall('data')\n",
    "    PATH='data/archive/'\n",
    "    df = pd.read_csv(os.path.join(PATH,\"overview.csv\"), index_col=0)\n",
    "    df['Contrast'] = df['Contrast'].map(lambda x: 1 if x else 0)\n",
    "\n",
    "    all_images_list = glob(os.path.join(PATH,'tiff_images','*.tif'))\n",
    "    np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape\n",
    "    jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)\n",
    "    check_contrast = re.compile(r'/tiff_images/ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT.tif')\n",
    "    \n",
    "    label = []\n",
    "    id_list = []\n",
    "    for image in all_images_list:\n",
    "        id_list.append(check_contrast.findall(image)[0][0])\n",
    "        label.append(check_contrast.findall(image)[0][1])\n",
    "\n",
    "    label_list = pd.DataFrame(label,id_list)\n",
    "    images = np.stack([jimread(i) for i in all_images_list],0)\n",
    "    \n",
    "    batch_size = 20\n",
    "    epochs = 5\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, label_list, test_size=0.1, random_state=0)\n",
    "    n_train, depth, width, height = X_train.shape\n",
    "    n_test,_,_,_ = X_test.shape\n",
    "    input_shape = (width,height,depth)\n",
    "    \n",
    "    input_train = X_train.reshape((n_train, width,height,depth))\n",
    "    input_train.astype('float32')\n",
    "    input_train = input_train / np.max(input_train)\n",
    "    \n",
    "    input_test = X_test.reshape(n_test, *input_shape)\n",
    "    input_test.astype('float32')\n",
    "    input_test = input_test / np.max(input_test)\n",
    "\n",
    "    output_train = keras.utils.to_categorical(y_train, 2)\n",
    "    output_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(50, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model2.add(MaxPooling2D(pool_size=(3, 3))) \n",
    "    model2.add(Conv2D(30, (4, 4), activation='relu', input_shape=input_shape))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    model2.fit(input_train, output_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(input_test, output_test))\n",
    "\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    model2.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(file_path: comp.InputPath('Tarball'), model_path: comp.InputPath('TFModel')):\n",
    "  import os\n",
    "  import pandas as pd\n",
    "  import tarfile\n",
    "  from glob import glob\n",
    "  import numpy as np\n",
    "  from skimage.io import imread\n",
    "  import re\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  import keras\n",
    "  from tensorflow import keras\n",
    "\n",
    "  model = keras.models.load_model(model_path)\n",
    "  tarfile.open(name=file_path, mode=\"r|gz\").extractall('data')\n",
    "  PATH='data/archive/'\n",
    "  \n",
    "  all_images_list = glob(os.path.join(PATH,'tiff_images','*.tif'))\n",
    "  np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape\n",
    "  jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)\n",
    "  check_contrast = re.compile(r'/tiff_images/ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT.tif')\n",
    "  label = []\n",
    "  id_list = []\n",
    "  for image in all_images_list:\n",
    "    id_list.append(check_contrast.findall(image)[0][0])\n",
    "    label.append(check_contrast.findall(image)[0][1])\n",
    "  label_list = pd.DataFrame(label,id_list)\n",
    "  images = np.stack([jimread(i) for i in all_images_list],0)\n",
    "    \n",
    "  X_train, X_test, y_train, y_test = train_test_split(images, label_list, test_size=0.1, random_state=0)\n",
    "  n_train, depth, width, height = X_train.shape\n",
    "  n_test,_,_,_ = X_test.shape\n",
    "  input_shape = (width,height,depth)\n",
    "    \n",
    "  input_test = X_test.reshape(n_test, *input_shape)\n",
    "  input_test.astype('float32')\n",
    "  input_test = input_test / np.max(input_test)\n",
    "\n",
    "  print(model.predict(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_merge_csv = kfp.components.create_component_from_func(\n",
    "    func=preprocess_csv,\n",
    "    output_component_file='component1.yaml',\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'scikit-image', 'numpy', 'glob2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_train_model = kfp.components.create_component_from_func(\n",
    "    func=train_model,\n",
    "    output_component_file='component2.yaml',\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas' ,'numpy', 'tensorflow', 'scikit-learn', 'scikit-image', 'keras', 'glob2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_predict_model = kfp.components.create_component_from_func(\n",
    "    func=predict_model,\n",
    "    output_component_file='component3.yaml',\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'numpy', 'tensorflow', 'scikit-learn', 'scikit-image', 'keras', 'glob2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pipeline(url):\n",
    "  web_downloader_task = web_downloader_op(url=url) \n",
    "  merge_csv_task = create_step_merge_csv(file=web_downloader_task.outputs['data'])\n",
    "  train_model_task = create_step_train_model(file=web_downloader_task.outputs['data'], file_csv=merge_csv_task.outputs['output_csv'])\n",
    "  predict_model_task = create_predict_model(file=web_downloader_task.outputs['data'], model=train_model_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/experiments/details/10db4384-249f-42b8-ae20-1c53ff5c3114\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/runs/details/b259bd22-f30f-4d5d-9f3a-bbb50388b45e\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=b259bd22-f30f-4d5d-9f3a-bbb50388b45e)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = kfp.Client(host='http://localhost:8080')\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    arguments={\n",
    "        'url': 'https://rancherdataset.blob.core.windows.net/dataset/archive.tar.gz'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7d8cb0326397c460ffed8c21d27be62f953c3ebe23192199009c94721ac0529"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
